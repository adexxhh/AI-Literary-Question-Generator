LitAI: Structural Manuscript Auditor
LitAI is an industry-grade, AI-powered literary assistant designed to perform deep structural audits on manuscripts. Unlike basic summarization tools, LitAI uses an Agentic RAG (Retrieval-Augmented Generation) pipeline to simulate the mind of a Senior Developmental Editor, identifying narrative inconsistencies and thematic gaps with precise source attribution.

Key Features
Semantic Section Marking: Automatically identifies and cites specific page numbers (e.g., [ğŸ“ Page 12]) using metadata-aware retrieval.

Editor Persona Engine: Leverages Gemini 3 Flash with thinking_level="medium" to generate critical questions, structural impacts, and expected narrative answers.

Fluid Intent Recognition: Distinguishes between factual queries (listing characters) and analytical requests (auditing pacing or themes).

High-Performance Vector Store: Utilizes FAISS (Facebook AI Similarity Search) for sub-second retrieval across large text corpora.

2026-Ready Stack: Built on the latest Gemini 3 Flash Preview architecture for superior zero-shot reasoning.

Tech Stack
Language: Python 3.10+

LLM: Google Gemini 3 Flash Preview

Orchestration: LangChain (LCEL)

Vector Database: FAISS (CPU)

UI Framework: Streamlit

PDF Processing: PyPDF with Metadata Extraction

Project Structure
Plaintext
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app.py           # Streamlit Frontend & Orchestration
â”‚   â”œâ”€â”€ preprocess.py    # Document Loading & Metadata Chunking
â”‚   â””â”€â”€ generator.py     # AI Persona & RAG Chain Logic
â”œâ”€â”€ .env                 # API Key Storage (Ignored by Git)
â”œâ”€â”€ requirements.txt     # Dependency List
â””â”€â”€ README.md            # Project Documentation
âš™ï¸ Installation & Setup
Clone the Repository:

Bash
git clone https://github.com/adexxhh/AI-Literary-Question-Generator.git
cd AI-Literary-Question-Generator
Set up Virtual Environment:

Bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
Install Dependencies:

Bash
pip install -r requirements.txt
Configure Environment Variables: Create a .env file and add your Google API Key:

Plaintext
GOOGLE_API_KEY=your_gemini_api_key_here
Run the Application:

Bash
streamlit run src/app.py


Engineering Highlights (For Evaluators)
Metadata Persistence: Implemented a custom pre-processing pipeline that attaches page-level metadata to document chunks, ensuring that the LLM maintains "spatial awareness" of the book.

Robust Extraction Logic: Designed a fail-safe parser to handle the complex JSON/List response formats of the Gemini 3 Preview API, ensuring 99.9% UI stability.

Context Optimization: Implemented a top-k retrieval strategy (k=5) with 2000-token chunks to maximize reasoning quality while minimizing token latency.
